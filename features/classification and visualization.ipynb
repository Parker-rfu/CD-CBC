{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aac35ff-27bb-47f7-afcd-c94d241ada78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fefe4ae-83af-4abf-bbcb-fb58fe9b3f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "Datasets=['Matek', 'Acevedo']\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681258db-aa56-4c5e-85d1-8b723d13ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32890, 768)\n"
     ]
    }
   ],
   "source": [
    "x = np.load('./X.npy')\n",
    "y = np.load('./y.npy')\n",
    "dataset = np.load('./dataset.npy')\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# 加载数据\n",
    "x = np.load('./X.npy')\n",
    "y = np.load('./y.npy')\n",
    "\n",
    "# 定义标签映射\n",
    "label_map = {\n",
    "    'basophil': 0,\n",
    "    'eosinophil': 1,\n",
    "    'erythroblast': 2,\n",
    "    'myeloblast': 3,\n",
    "    'promyelocyte': 4,\n",
    "    'myelocyte': 5,\n",
    "    'metamyelocyte': 6,\n",
    "    'neutrophil_banded': 7,\n",
    "    'neutrophil_segmented': 8,\n",
    "    'monocyte': 9,\n",
    "    'lymphocyte_typical': 10,\n",
    "    'lymphocyte_atypical': 11,\n",
    "    'smudge_cell': 12,\n",
    "}\n",
    "\n",
    "# 反向映射：从数字到细胞名称\n",
    "inverse_label_map = {v: k.replace(\"_\", \" \") for k, v in label_map.items()}\n",
    "\n",
    "# 使用 t-SNE 降维到2D空间\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000)\n",
    "x_tsne = tsne.fit_transform(x)\n",
    "\n",
    "# 定义13种易于区分的颜色\n",
    "colors = [\n",
    "    '#956CB9', '#F9BB7A', '#C4AFD2', '#FE8111', '#8C554C', '#FA9A92', \n",
    "    '#97E187', '#39A035', '#AFC7E6', '#2377B3', '#D3292C', '#5DD1DD', \n",
    "    '#D0D065'\n",
    "]\n",
    "cmap = ListedColormap(colors[:13])  # 确保只取13种颜色\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(x_tsne[:, 0], x_tsne[:, 1], c=y, cmap=cmap, s=5, alpha=0.8)\n",
    "\n",
    "# # 创建图例\n",
    "# handles = [\n",
    "#     plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=8) \n",
    "#     for color in colors[:13]\n",
    "# ]\n",
    "# labels = [inverse_label_map[i] for i in range(13)]\n",
    "# plt.legend(handles, labels, loc='best', title=\"Cell Types\", fontsize=10, title_fontsize=12)\n",
    "\n",
    "# 去除标题、坐标轴和网格\n",
    "plt.gca().set_title('')\n",
    "plt.gca().set_xlabel('')\n",
    "plt.gca().set_ylabel('')\n",
    "plt.gca().grid(False)\n",
    "\n",
    "# 去除所有坐标轴\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "# 保存为 PDF\n",
    "plt.savefig(\"t-SNE.pdf\", format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2efe79fc-31bc-4357-860b-0a63fa1fb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess for xgboost\n",
    "y[y==10]=-1\n",
    "y[y==3]=10\n",
    "y[y==-1]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7ab76d-23fa-458f-b382-f4611833e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X={}\n",
    "Y={}\n",
    "for ds in range(len(Datasets)):\n",
    "    X[ds] = x[dataset == ds]\n",
    "    Y[ds] = y[dataset == ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f4c3b38-c804-4da8-b31f-69bd0860ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier :\n",
      "train on Matek :\n",
      "test on Matek, acc mean : 0.945386, acc std : 0.003678\n",
      "test on Acevedo, acc mean : 0.367545, acc std : 0.007421\n",
      "train on Acevedo :\n",
      "test on Matek, acc mean : 0.425933, acc std : 0.01854\n",
      "test on Acevedo, acc mean : 0.870179, acc std : 0.009402\n"
     ]
    }
   ],
   "source": [
    "result={ds : {ds : np.zeros(5) for ds in Datasets} for ds in Datasets}\n",
    "cm=[np.zeros((13,13)), np.zeros((11,11))]\n",
    "print(\"RandomForestClassifier :\")\n",
    "for ds in range(len(Datasets)):\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X[ds], Y[ds])):\n",
    "        rf = RandomForestClassifier(n_estimators=200, max_depth=16, n_jobs=64, random_state=seed)\n",
    "        rf.fit(X[ds][train_index],Y[ds][train_index])\n",
    "        pred = rf.predict(X[ds][test_index])\n",
    "        accuracy = accuracy_score(Y[ds][test_index], pred)\n",
    "        result[Datasets[ds]][Datasets[ds]][fold] = accuracy\n",
    "        for val_ds in range(len(Datasets)):\n",
    "            if val_ds == ds:\n",
    "                continue\n",
    "            pred = rf.predict(x[dataset == val_ds])\n",
    "            # cm[val_ds] += confusion_matrix(y[dataset == val_ds], pred)\n",
    "            accuracy = accuracy_score(y[dataset == val_ds], pred)\n",
    "            result[Datasets[ds]][Datasets[val_ds]][fold] = accuracy\n",
    "\n",
    "for ds in Datasets:\n",
    "    if ds != 'SYSU3H':\n",
    "        print(\"train on {} :\".format(ds))\n",
    "        for val_ds in Datasets:\n",
    "            print(\"test on {}, acc mean : {:.6}, acc std : {:.4}\".format(val_ds, result[ds][val_ds].mean(), result[ds][val_ds].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694871b5-0748-40be-abb4-430db34a9e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [10:59:22] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on Matek :\n",
      "test on Matek, acc mean : 0.954652, acc std : 0.003707\n",
      "test on Acevedo, acc mean : 0.422911, acc std : 0.03275\n",
      "train on Acevedo :\n",
      "test on Matek, acc mean : 0.355546, acc std : 0.01374\n",
      "test on Acevedo, acc mean : 0.882213, acc std : 0.009202\n"
     ]
    }
   ],
   "source": [
    "result={ds : {ds : np.zeros(5) for ds in Datasets} for ds in Datasets}\n",
    "print(\"XGBoost :\")\n",
    "for ds in range(len(Datasets)):\n",
    "    if Datasets[ds] != 'SYSU3H':\n",
    "        for fold, (train_index, test_index) in enumerate(kf.split(X[ds], Y[ds])):\n",
    "            xgboost = XGBClassifier(tree_method = \"hist\", device = \"cuda\",random_state=seed)\n",
    "            xgboost.fit(X[ds][train_index],Y[ds][train_index])\n",
    "            pred = xgboost.predict(X[ds][test_index])\n",
    "            accuracy = accuracy_score(Y[ds][test_index], pred)\n",
    "            result[Datasets[ds]][Datasets[ds]][fold] = accuracy\n",
    "            for val_ds in range(len(Datasets)):\n",
    "                if val_ds == ds:\n",
    "                    continue\n",
    "                pred = xgboost.predict(x[dataset == val_ds])\n",
    "                accuracy = accuracy_score(y[dataset == val_ds], pred)\n",
    "                result[Datasets[ds]][Datasets[val_ds]][fold] = accuracy\n",
    "\n",
    "    \n",
    "for ds in Datasets:\n",
    "    if ds != 'SYSU3H':\n",
    "        print(\"train on {} :\".format(ds))\n",
    "        for val_ds in Datasets:\n",
    "            print(\"test on {}, acc mean : {:.6}, acc std : {:.4}\".format(val_ds, result[ds][val_ds].mean(), result[ds][val_ds].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46039b4-459a-40ff-b28a-799782309c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(poly) :\n",
      "train on Matek :\n",
      "test on Matek, acc mean : 0.958522, acc std : 0.00266\n",
      "test on Acevedo, acc mean : 0.507213, acc std : 0.01042\n",
      "train on Acevedo :\n",
      "test on Matek, acc mean : 0.400131, acc std : 0.008172\n",
      "test on Acevedo, acc mean : 0.890326, acc std : 0.00587\n"
     ]
    }
   ],
   "source": [
    "result={ds : {ds : np.zeros(5) for ds in Datasets} for ds in Datasets}\n",
    "print('SVM(poly) :')\n",
    "for ds in range(len(Datasets)):\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X[ds], Y[ds])):\n",
    "        scaler = StandardScaler()\n",
    "        svc = SVC(kernel='poly', random_state=seed)\n",
    "        svc.fit(scaler.fit_transform(X[ds][train_index]),Y[ds][train_index])\n",
    "        pred = svc.predict(scaler.transform(X[ds][test_index]))\n",
    "        accuracy = accuracy_score(Y[ds][test_index], pred)\n",
    "        result[Datasets[ds]][Datasets[ds]][fold] = accuracy\n",
    "        for val_ds in range(len(Datasets)):\n",
    "            if val_ds == ds:\n",
    "                continue\n",
    "            pred = svc.predict(scaler.transform(x[dataset == val_ds]))\n",
    "            accuracy = accuracy_score(y[dataset == val_ds], pred)\n",
    "            result[Datasets[ds]][Datasets[val_ds]][fold] = accuracy\n",
    "\n",
    "    \n",
    "for ds in Datasets:\n",
    "    if ds != 'SYSU3H':\n",
    "        print(\"train on {} :\".format(ds))\n",
    "        for val_ds in Datasets:\n",
    "            print(\"test on {}, acc mean : {:.6}, acc std : {:.4}\".format(val_ds, result[ds][val_ds].mean(), result[ds][val_ds].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffa22c6-90cc-4bef-9e45-3cfa7a871ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(linear) :\n",
      "train on Matek :\n",
      "test on Matek, acc mean : 0.948111, acc std : 0.002211\n",
      "test on Acevedo, acc mean : 0.519961, acc std : 0.06289\n",
      "train on Acevedo :\n",
      "test on Matek, acc mean : 0.617016, acc std : 0.02109\n",
      "test on Acevedo, acc mean : 0.893282, acc std : 0.004845\n"
     ]
    }
   ],
   "source": [
    "result={ds : {ds : np.zeros(5) for ds in Datasets} for ds in Datasets}\n",
    "print('SVM(linear) :')\n",
    "for ds in range(len(Datasets)):\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X[ds], Y[ds])):\n",
    "        scaler = StandardScaler()\n",
    "        svc = SVC(kernel='linear', random_state=seed)\n",
    "        svc.fit(scaler.fit_transform(X[ds][train_index]),Y[ds][train_index])\n",
    "        pred = svc.predict(scaler.transform(X[ds][test_index]))\n",
    "        accuracy = accuracy_score(Y[ds][test_index], pred)\n",
    "        result[Datasets[ds]][Datasets[ds]][fold] = accuracy\n",
    "        for val_ds in range(len(Datasets)):\n",
    "            if val_ds == ds:\n",
    "                continue\n",
    "            pred = svc.predict(scaler.transform(x[dataset == val_ds]))\n",
    "            accuracy = accuracy_score(y[dataset == val_ds], pred)\n",
    "            # if val_ds==2 and ds == 1:\n",
    "            #     print(pred)\n",
    "            result[Datasets[ds]][Datasets[val_ds]][fold] = accuracy\n",
    "\n",
    "    \n",
    "for ds in Datasets:\n",
    "    if ds =='SYSU3H':\n",
    "        continue\n",
    "    print(\"train on {} :\".format(ds))\n",
    "    for val_ds in Datasets:\n",
    "        print(\"test on {}, acc mean : {:.6}, acc std : {:.4}\".format(val_ds, result[ds][val_ds].mean(), result[ds][val_ds].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae23cfd-8727-4be0-884e-74513fe62d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp :\n",
      "train on Matek :\n",
      "test on Matek, acc mean : 0.959503, acc std : 0.002268\n",
      "test on Acevedo, acc mean : 0.565138, acc std : 0.0127\n",
      "train on Acevedo :\n",
      "test on Matek, acc mean : 0.684275, acc std : 0.02959\n",
      "test on Acevedo, acc mean : 0.893626, acc std : 0.004349\n"
     ]
    }
   ],
   "source": [
    "result={ds : {ds : np.zeros(5) for ds in Datasets} for ds in Datasets}\n",
    "print('mlp :')\n",
    "for ds in range(len(Datasets)):\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X[ds], Y[ds])):\n",
    "        scaler = StandardScaler()\n",
    "        mlp = MLPClassifier(max_iter=1000, early_stopping=True, random_state=seed)\n",
    "        mlp.fit(scaler.fit_transform(X[ds][train_index]),Y[ds][train_index])\n",
    "        pred = mlp.predict(scaler.transform(X[ds][test_index]))\n",
    "        accuracy = accuracy_score(Y[ds][test_index], pred)\n",
    "        result[Datasets[ds]][Datasets[ds]][fold] = accuracy\n",
    "        for val_ds in range(len(Datasets)):\n",
    "            if val_ds == ds:\n",
    "                continue\n",
    "            pred = mlp.predict(scaler.transform(x[dataset == val_ds]))\n",
    "            accuracy = accuracy_score(y[dataset == val_ds], pred)\n",
    "            result[Datasets[ds]][Datasets[val_ds]][fold] = accuracy\n",
    "\n",
    "    \n",
    "for ds in Datasets:\n",
    "    if ds != 'SYSU3H':\n",
    "        print(\"train on {} :\".format(ds))\n",
    "        for val_ds in Datasets:\n",
    "            print(\"test on {}, acc mean : {:.6}, acc std : {:.4}\".format(val_ds, result[ds][val_ds].mean(), result[ds][val_ds].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3362312f-0ba8-4ad1-bebd-af653029ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on Matek :\n",
      "test on Matek, acc mean : 0.954816, acc std : 0.001304\n",
      "test on Acevedo, acc mean : 0.415691, acc std : 0.07102\n",
      "train on Acevedo :\n",
      "test on Matek, acc mean : 0.682826, acc std : 0.02353\n",
      "test on Acevedo, acc mean : 0.894933, acc std : 0.002537\n"
     ]
    }
   ],
   "source": [
    "result={ds : {ds : np.zeros(5) for ds in Datasets} for ds in Datasets}\n",
    "print('LogisticRegression :')\n",
    "for ds in range(len(Datasets)):\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X[ds], Y[ds])):\n",
    "        scaler = StandardScaler()\n",
    "        lr = LogisticRegression(max_iter=500, random_state=seed)\n",
    "        lr.fit(scaler.fit_transform(X[ds][train_index]),Y[ds][train_index])\n",
    "        pred = lr.predict(scaler.transform(X[ds][test_index]))\n",
    "        accuracy = accuracy_score(Y[ds][test_index], pred)\n",
    "        result[Datasets[ds]][Datasets[ds]][fold] = accuracy\n",
    "        for val_ds in range(len(Datasets)):\n",
    "            if val_ds == ds:\n",
    "                continue\n",
    "            pred = lr.predict(scaler.transform(x[dataset == val_ds]))\n",
    "            accuracy = accuracy_score(y[dataset == val_ds], pred)\n",
    "            result[Datasets[ds]][Datasets[val_ds]][fold] = accuracy\n",
    "\n",
    "    \n",
    "for ds in Datasets:\n",
    "    if ds != 'SYSU3H':\n",
    "        print(\"train on {} :\".format(ds))\n",
    "        for val_ds in Datasets:\n",
    "            print(\"test on {}, acc mean : {:.6}, acc std : {:.4}\".format(val_ds, result[ds][val_ds].mean(), result[ds][val_ds].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6ffc1-71b0-4e96-9c9a-5c52019c4aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
